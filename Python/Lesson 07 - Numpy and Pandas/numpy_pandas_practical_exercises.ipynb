{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29a27d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python executable: c:\\Users\\Ray\\.venv\\Scripts\\python.exe\n",
      "ipykernel available: True\n",
      "pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "# Kernel / venv verification\n",
    "# Run this first. No need to edit\n",
    "import sys, importlib\n",
    "print('python executable:', sys.executable)\n",
    "print('ipykernel available:', importlib.util.find_spec('ipykernel') is not None)\n",
    "import pandas as pd\n",
    "print('pandas version:', pd.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378edacb",
   "metadata": {},
   "source": [
    "# Refresher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31372464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Day,High,Low,Precipitation,Snow\\n', 'January 1,38.0,32.0,0.08,0.4\\n', 'January 2,35.0,32.0,0.0,0.0\\n', 'January 3,41.0,32.0,0.0,0.0\\n', 'January 4,36.0,27.0,0.0,0.0\\n']\n",
      "\n",
      "Daily high temperatures: [38.0, 35.0, 41.0, 36.0, 38.0, 35.0, 36.0, 40.0, 50.0, 42.0, 43.0, 46.0, 46.0, 29.0, 22.0, 19.0, 20.0, 29.0, 27.0, 19.0, 25.0, 39.0, 45.0, 56.0, 59.0, 64.0, 47.0, 46.0, 36.0, 40.0, 45.0, 48.0, 47.0, 47.0, 55.0, 48.0, 46.0, 54.0, 63.0, 63.0, 63.0, 48.0, 46.0, 44.0, 39.0, 56.0, 39.0, 29.0, 37.0, 42.0, 52.0, 59.0, 49.0, 58.0, 37.0, 47.0, 65.0, 66.0, 64.0, 39.0, 52.0, 53.0, 66.0, 74.0, 75.0, 62.0, 50.0, 65.0, 56.0, 41.0, 52.0, 68.0, 71.0, 74.0, 61.0, 61.0, 56.0, 36.0, 47.0, 50.0, 41.0, 54.0, 43.0, 48.0, 67.0, 54.0, 61.0, 52.0, 53.0, 59.0, 59.0, 64.0, 63.0, 62.0, 47.0, 43.0, 54.0, 61.0, 74.0, 76.0, 66.0, 69.0, 60.0, 60.0, 82.0, 74.0, 80.0, 82.0, 73.0, 70.0, 59.0, 49.0, 62.0, 68.0, 61.0, 57.0, 70.0, 81.0, 83.0, 83.0, 73.0, 80.0, 85.0, 87.0, 65.0, 78.0, 73.0, 78.0, 81.0, 65.0, 62.0, 60.0, 66.0, 80.0, 68.0, 78.0, 76.0, 70.0, 81.0, 85.0, 86.0, 87.0, 84.0, 79.0, 84.0, 83.0, 82.0, 78.0, 75.0, 65.0, 69.0, 74.0, 80.0, 69.0, 82.0, 87.0, 80.0, 79.0, 73.0, 78.0, 75.0, 67.0, 72.0, 80.0, 87.0, 82.0, 80.0, 89.0, 94.0, 94.0, 89.0, 92.0, 94.0, 94.0, 86.0, 82.0, 84.0, 85.0, 80.0, 88.0, 85.0, 86.0, 78.0, 86.0, 91.0, 89.0, 87.0, 86.0, 89.0, 92.0, 92.0, 92.0, 79.0, 91.0, 94.0, 93.0, 93.0, 93.0, 85.0, 81.0, 84.0, 88.0, 85.0, 75.0, 84.0, 85.0, 85.0, 82.0, 89.0, 92.0, 86.0, 83.0, 92.0, 91.0, 85.0, 82.0, 87.0, 90.0, 91.0, 78.0, 85.0, 84.0, 79.0, 77.0, 78.0, 81.0, 83.0, 86.0, 83.0, 85.0, 81.0, 70.0, 69.0, 72.0, 76.0, 82.0, 87.0, 87.0, 91.0, 94.0, 93.0, 92.0, 94.0, 83.0, 87.0, 73.0, 75.0, 79.0, 82.0, 86.0, 69.0, 69.0, 75.0, 82.0, 85.0, 84.0, 83.0, 86.0, 85.0, 80.0, 80.0, 79.0, 84.0, 87.0, 89.0, 85.0, 78.0, 78.0, 79.0, 75.0, 74.0, 77.0, 70.0, 67.0, 68.0, 69.0, 76.0, 80.0, 74.0, 83.0, 63.0, 68.0, 65.0, 62.0, 70.0, 70.0, 77.0, 57.0, 53.0, 52.0, 61.0, 68.0, 73.0, 74.0, 77.0, 82.0, 77.0, 61.0, 68.0, 61.0, 56.0, 65.0, 78.0, 77.0, 80.0, 65.0, 60.0, 64.0, 73.0, 81.0, 72.0, 65.0, 65.0, 57.0, 61.0, 61.0, 51.0, 55.0, 47.0, 52.0, 51.0, 55.0, 61.0, 62.0, 63.0, 40.0, 43.0, 47.0, 45.0, 56.0, 56.0, 46.0, 41.0, 36.0, 28.0, 32.0, 35.0, 35.0, 43.0, 35.0, 30.0, 40.0, 55.0, 55.0, 59.0, 49.0, 31.0, 31.0, 41.0, 43.0, 58.0, 57.0, 40.0, 36.0, 35.0, 44.0, 27.0, 43.0, 43.0, 41.0, 45.0, 53.0, 64.0, 65.0, 50.0, 49.0]\n",
      "\n",
      "Average high temperature: 65.88524590163935\n"
     ]
    }
   ],
   "source": [
    "#open the file \"pittsburgh-weather-2024.csv\"\n",
    "with open('pittsburgh-weather-2024.csv', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "#look at the first 5 lines of the file\n",
    "print(lines[:5])\n",
    "print()\n",
    "\n",
    "#extracting daily high temperatures from the CSV file\n",
    "daily_highs = []\n",
    "for line in lines[1:]: #first line is the header\n",
    "    row = line.strip().split(',')\n",
    "    daily_highs.append(float(row[1]))\n",
    "print(\"Daily high temperatures:\", daily_highs)\n",
    "print()\n",
    "\n",
    "#Using list of daily highs to calculate the average high temperature\n",
    "total_high = 0\n",
    "for t in daily_highs:\n",
    "    total_high += t\n",
    "\n",
    "average_high = total_high / (len(daily_highs))\n",
    "\n",
    "print(\"Average high temperature:\", average_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f767ff5e",
   "metadata": {},
   "source": [
    "# 1D and 2D arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a7a2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c210945f",
   "metadata": {},
   "source": [
    "### 1D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9e5d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a29b3677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "print(arr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e32577",
   "metadata": {},
   "source": [
    "**array.dtype** : This tells you the data type of the elements inside the array.\n",
    "\n",
    "**type(array)** : This tells you the type of the object itself — i.e., what kind of Python object the array is.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92373698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(arr1.dtype)\n",
    "print(type(arr1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808eaf0b",
   "metadata": {},
   "source": [
    "### 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cac14d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.array([[1, 2, 3],\n",
    "                [4, 5, 6]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6db681ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "print(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02246547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(type(arr2))\n",
    "print(arr2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920c5c41",
   "metadata": {},
   "source": [
    "### Upcasting\n",
    "In NumPy, **Upcasting** refers to converting mixed data types to a single, more general type (like converting integers to strings) to ensure the array is homogeneous.\n",
    "\n",
    "specific -> general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "023f83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr3 = np.array([[1, 2, 3, 4, 5],\n",
    "                 ['one', 'two', 'three', 'four', 'five']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a39f7849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1' '2' '3' '4' '5']\n",
      " ['one' 'two' 'three' 'four' 'five']]\n"
     ]
    }
   ],
   "source": [
    "print(arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0efb2f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<U21\n"
     ]
    }
   ],
   "source": [
    "print(type(arr3))\n",
    "print(arr3.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b502c4c4",
   "metadata": {},
   "source": [
    "That means NumPy has inferred the array’s data type as Unicode string with up to 11 characters.\n",
    "\n",
    "NumPy sees mixed types (integers and strings), and it automatically upcasts the integers to strings so all elements share a common type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fc1ffb",
   "metadata": {},
   "source": [
    "# Creating Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35125e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42fd36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e442e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3403b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d213e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a413ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3342ef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr2[0]) # accessing the first array\n",
    "print(type(arr2[0]))\n",
    "print(type(arr2[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da69c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr2[1]) # accessing the second array\n",
    "print(type(arr2[1]))\n",
    "print(type(arr2[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088b2221",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr2[0, 0]) # accessing the first element\n",
    "print(type(arr2[0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b5fb5c",
   "metadata": {},
   "source": [
    "# Array Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58514fd8",
   "metadata": {},
   "source": [
    "### Element-wise math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772fae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428c601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887eb54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b76db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4962652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf4d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908f1b93",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e92c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51be8142",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(10)\n",
    "arr + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262f98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(10))\n",
    "arr + np.array(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e448fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([[10, 10, 10],[10, 10, 10],[10, 10, 10]]))\n",
    "arr + np.array([[10, 10, 10],[10, 10, 10],[10, 10, 10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e7cdc6",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3411617",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003c1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffa78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb179368",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4405e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ce615",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27014e",
   "metadata": {},
   "source": [
    "Also works on 2D Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219cc080",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.array([[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]])\n",
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f68f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831af18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e8c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7e548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa79c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(arr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd77214d",
   "metadata": {},
   "source": [
    "# Array Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493719ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf7abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170fbfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f9a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741fce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10651e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2[1,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fcdff8",
   "metadata": {},
   "source": [
    "### Boolean Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a0a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[arr >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bcf879",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2[arr2 % 2 == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087fdb47",
   "metadata": {},
   "source": [
    "### Shape and Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2e0ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr)\n",
    "print(arr.shape)\n",
    "print(arr.size)\n",
    "print(arr.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr2)\n",
    "print(arr2.shape)\n",
    "print(arr2.size)\n",
    "print(arr2.ndim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7c0a8e",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f04c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2.reshape(3, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb18206",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2.reshape(9,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be91ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53603d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([[1, 2, 3],[4,5,6]])\n",
    "\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb65be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "array.reshape(3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a04343c",
   "metadata": {},
   "source": [
    "# Numpy Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9af5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(daily_highs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aca0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using np.array to find average daily high\n",
    "daily_highs_array = np.array(daily_highs)\n",
    "average_high = np.mean(daily_highs_array)\n",
    "\n",
    "print(\"Average high temperature:\", average_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eea8a4f",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e50d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a9d7ac",
   "metadata": {},
   "source": [
    "## Creating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21167f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_highs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e4c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgh_weather = pd.Series(    data=daily_highs,\n",
    "    name='Pittsburgh Daily Highs'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgh_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f77021",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  # Show all rows in the Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a7465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgh_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf41282",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563563f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Day': [f'Day {i+1}' for i in range(len(daily_highs))],\n",
    "    'High': daily_highs\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b20b307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c02839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pittsburgh-weather-2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa73b12",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075b434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901817ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a955b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874fb5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8fdd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9967e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pittsburgh-weather-2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8738d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20591fe9",
   "metadata": {},
   "source": [
    "# Selecting and Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6cedca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b01eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Day', 'Snow']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066057dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Day'] == 'December 13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa3466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['High'] >= 89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Low'] == 13.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993205da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb6b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3516b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['December 13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e843652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Day', inplace = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['January 4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d1177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[3] #Doesn't work after setting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84697f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3] # Still works with iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79970ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aa9229",
   "metadata": {},
   "source": [
    "## Pandas Exercise \n",
    "\n",
    "Load all_olympic_medalists.csv\n",
    "\n",
    "Do the following tasks/ Answer the following questions:\n",
    "1. Show the first 5 rows and the last 5 rows.\n",
    "2. How many rows are in the dataset?\n",
    "3. Are there any missing values in any of the columns? \n",
    "4. How many total medals are recorded in the dataset?\n",
    "5. How many medals were awarded in the first Olympic year (1896)? How would you do this if you didn't know the first year?\n",
    "6. How many medals has the US won?\n",
    "7. What years were medals awarded for Rugby?\n",
    "8. What was the first year women were included?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d88807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_olympic_medalists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dbe812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec6362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the last 5 rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c18de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any missing values in any of the columns?\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c33747",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de56aa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the missing values in the 'medal' column\n",
    "df[df['medal'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many total medals are recorded in the dataset?\n",
    "df['medal'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a8c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't use len() -- includes NaN values\n",
    "len(df['medal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944bf540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many medals were awarded in the first Olympic year (1896)?\n",
    "df[df['year'] == df['year'].min()]['medal'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c1df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. How many medals has the US won?\n",
    "df[df['country'] == 'United States']['medal'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What years did anyone medal for \"Rugby\"?\n",
    "df[df['sport'] == 'Rugby']['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786965c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the first year women were included?\n",
    "df[df['event_gender'] == 'Women\\'s']['year'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e82bd4",
   "metadata": {},
   "source": [
    "## Pandas Cleaning Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c0dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('all_olympic_medalists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2405e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b88be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show missing values in the 'medal' column\n",
    "df[df['medal'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8114062",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna({'country': 'Unknown'}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eeb24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['medal'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad62b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with missing values in the 'medal' column\n",
    "df.dropna(subset=['medal'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd85b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['medal'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac7462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef89e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'event_gender':'gender'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c72f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fa7878",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['year'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70d4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760cea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event'] = df['gender']+ ' ' + df['event_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f89e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7650f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to convert year (XXXX) to Y format\n",
    "def convert_year_to_datetime(year):\n",
    "    return pd.to_datetime(year, format='%Y')\n",
    "\n",
    "df['year'] = df['year'].apply(convert_year_to_datetime)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ebe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change 'year' column back to just the year\n",
    "df['year'] = df['year'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e3872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d6c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df = df.groupby('country').get_group('United States').groupby('year').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04749f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  # Show all rows in the Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71dc021",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e41179",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd079ef5",
   "metadata": {},
   "source": [
    "# Matplotlib      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d991dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c514485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the number of medals won by the US over the years\n",
    "us_df = df.groupby('country').get_group('United States').groupby('year').size()\n",
    "us_df.plot(kind='bar', figsize=(12, 6), color='green', title='Number of Medals Won by the US')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30e21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot number of  medalists in the Olympics over the years\n",
    "us_golds = df.groupby('country').get_group('United States').groupby('medal').get_group('Gold').groupby('year').size()\n",
    "us_golds.plot(kind='bar', figsize=(12, 6), color='gold', title='Number of Gold Medals Awarded to the US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbf1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_golds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c37fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the number of medals won by US in the Olympics split by medal type\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158c6d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for US women\n",
    "us = df[ (df['country_code'] == 'USA') ]\n",
    "\n",
    "# Group by year and medal type, then count\n",
    "medal_counts = us.groupby(['year', 'medal']).size().unstack(fill_value=0)\n",
    "\n",
    "# Reorder medal columns: Bronze, Silver, Gold\n",
    "medal_counts = medal_counts[['Bronze', 'Silver', 'Gold']]\n",
    "\n",
    "# Plot the stacked bar chart\n",
    "medal_counts.plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    figsize=(12, 6),\n",
    "    color={'Gold': \"#F7D722\", 'Silver': '#C0C0C0', 'Bronze': '#CD7F32'}\n",
    ")\n",
    "\n",
    "plt.title('US Olympic Medals Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Medals')\n",
    "plt.legend(title='Medal')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc901015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5202a3dc",
   "metadata": {},
   "source": [
    "# Pandas Data Cleaning Exercise\n",
    "\n",
    "In all questions referring to gross, use the adjusted gross (in 2022 dollars)\n",
    "\n",
    "- Drop the column 'Ref.'\n",
    "- Rename 'Adjusted gross (in 2022 dollars)' to 'Adjusted gross'.\n",
    "- List the artists and the number of times they appear in the rankings.\n",
    "- What Taylor Swift tours made the rankings?\n",
    "- Clean the actual gross and adjusted gross columns and convert them to float.\n",
    "- What is the total adjusted gross from all 20 concerts?\n",
    "- Calculate average gross/show for each rank using the adjusted gross. \n",
    "- How much has Taylor Swift earned from the concerts on this list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929867a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('top-20-womens-tours.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58fb3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ace95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c64dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Drop the column 'Ref.'\n",
    "df.drop(columns=['Ref.'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1afa68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Rename 'Adjusted gross (in 2022 dollars)' to 'Adjusted gross'.\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e2f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Adjusted gross (in 2022 dollars)': 'Adjusted gross'}, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e162d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- List the artists and the number of times they appear in the rankings.\n",
    "df['Artist'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Artist')['Tour title'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74a0c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- What Taylor Swift tours made the rankings?\n",
    "taylor = df.groupby('Artist').get_group('Taylor Swift')\n",
    "taylor['Tour title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Artist'] == 'Taylor Swift']['Tour title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7ea8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Clean the actual gross and adjusted gross columns and convert them to float.\n",
    "def clean_currency(value):\n",
    "    if isinstance(value, str):\n",
    "        value = value.replace('$', '').replace(',', '')\n",
    "        return float(value)\n",
    "    \n",
    "df['Actual gross'] = df['Actual gross'].apply(clean_currency)\n",
    "df['Adjusted gross'] = df['Adjusted gross'].apply(clean_currency)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a6dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- What is the total adjusted gross from all 20 concerts?\n",
    "df['Adjusted gross'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b706c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Calculate average gross/show for each rank using the adjusted gross. \n",
    "df['Average gross'] = round(df['Adjusted gross'] / df['Shows'], 2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b67827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- How much has Taylor Swift earned from the concerts on this list?\n",
    "df[df['Artist'] == 'Taylor Swift']['Adjusted gross'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Artist')['Adjusted gross'].sum().loc['Taylor Swift']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c52da7b",
   "metadata": {},
   "source": [
    "### Merging and Concatenation (pd.merge vs pd.concat) \n",
    "\n",
    "When combining data:\n",
    "- Use **pd.concat** to stack DataFrames (add rows or columns). Good for appending new records or combining same-schema data.\n",
    "- Use **pd.merge** (SQL-style joins) when you need to join on keys (one-to-many, many-to-one, etc.).\n",
    "\n",
    "This section shows examples and quick exercises to practice.\n",
    "# Merge examples\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrames for merges\n",
    "df_people = pd.DataFrame({\n",
    "    'person_id': [1, 2, 3],\n",
    "    'name': ['Alice', 'Bob', 'Charlie']\n",
    "})\n",
    "\n",
    "df_scores = pd.DataFrame({\n",
    "    'person_id': [1, 2, 2, 4],\n",
    "    'score': [95, 80, 82, 77]\n",
    "})\n",
    "\n",
    "print(\"people\\n\", df_people)\n",
    "print(\"\\nscores\\n\", df_scores)\n",
    "\n",
    "# Inner join (only matching keys)\n",
    "inner = pd.merge(df_people, df_scores, on='person_id', how='inner')\n",
    "print(\"\\ninner merge:\\n\", inner)\n",
    "\n",
    "# Left join (all people, scores where available)\n",
    "left = pd.merge(df_people, df_scores, on='person_id', how='left')\n",
    "print(\"\\nleft merge:\\n\", left)\n",
    "\n",
    "# Demonstrate suffixes and multiple keys\n",
    "\n",
    "df_a = pd.DataFrame({'id':[1,2], 'val':[10,20]})\n",
    "df_b = pd.DataFrame({'id':[1,2], 'val':[100,200]})\n",
    "joined = pd.merge(df_a, df_b, on='id', suffixes=('_a', '_b'))\n",
    "print(\"\\nsuffixes example:\\n\", joined)\n",
    "\n",
    "# Use indicator to see join origin\n",
    "print('\\nouter merge with indicator:\\n', pd.merge(df_people, df_scores, on='person_id', how='outer', indicator=True))\n",
    "# Concatenation examples\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'A':[1,2], 'B':[3,4]})\n",
    "df2 = pd.DataFrame({'A':[5,6], 'B':[7,8]})\n",
    "# Stack rows (vertical)\n",
    "v = pd.concat([df1, df2], ignore_index=True)\n",
    "print(\"vertical concat:\\n\", v)\n",
    "\n",
    "# Concatenate with mismatched columns (outer join style)\n",
    "df3 = pd.DataFrame({'A':[9], 'C':[10]})\n",
    "v2 = pd.concat([df1, df3], ignore_index=True, sort=False)\n",
    "print(\"\\nconcat with mismatched columns:\\n\", v2)\n",
    "\n",
    "# Concatenate side-by-side (axis=1)\n",
    "h = pd.concat([df1, df2], axis=1)\n",
    "print(\"\\nhorizontal concat (axis=1):\\n\", h)\n",
    "\n",
    "# keys to create hierarchical index when concatenating multiple groups\n",
    "grouped = pd.concat([df1, df2], keys=['g1','g2'])\n",
    "print(\"\\nconcat with keys:\\n\", grouped)\n",
    "### Exercises (try before peeking at solutions) \n",
    "\n",
    "1. Use `df_olympics` and the existing `df_continents` example: left-merge them and compute medal counts per continent.\n",
    "2. Given two DataFrames with the same columns but different rows, concatenate them and reset the index.\n",
    "3. Find a case that produces a many-to-many join (duplicate keys on both frames) and observe the result — what happens?\n",
    "\n",
    "(Hints: use `indicator=True` and `validate='one_to_many'` to check behavior.)\n",
    "# Solutions (run to check)\n",
    "import pandas as pd\n",
    "# 1. Merge olympics -> continents, count medals per continent\n",
    "if 'df_olympics' in globals() and 'df_continents' in globals():\n",
    "    merged = pd.merge(df_olympics, df_continents, on='country_code', how='left')\n",
    "    print(\"Medals by continent:\\n\", merged.groupby('continent')['medal'].count().sort_values(ascending=False).head())\n",
    "else:\n",
    "    print(\"df_olympics or df_continents not found in this kernel - run earlier cells first.\")\n",
    "\n",
    "# 2. Concatenate two frames and reset index\n",
    "a = pd.DataFrame({'x':[1,2]})\n",
    "b = pd.DataFrame({'x':[3,4]})\n",
    "print(\"\\nconcat and reset:\\n\", pd.concat([a,b], ignore_index=True))\n",
    "\n",
    "# 3. Many-to-many example\n",
    "left = pd.DataFrame({'k':[1,1],'v_left':[10,20]})\n",
    "right = pd.DataFrame({'k':[1,1],'v_right':[100,200]})\n",
    "print(\"\\nmany-to-many join (cartesian product):\\n\", pd.merge(left, right, on='k'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49152742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Merging Data\n",
    "# First, ensure we have the olympic data loaded\n",
    "df_olympics = pd.read_csv('all_olympic_medalists.csv')\n",
    "\n",
    "# Create a small DataFrame to map codes to continents (just a sample)\n",
    "continent_data = {\n",
    "    'country_code': ['USA', 'CHN', 'GBR', 'AUS', 'CAN', 'FRA', 'GER', 'JPN'],\n",
    "    'continent': ['North America', 'Asia', 'Europe', 'Oceania', 'North America', 'Europe', 'Europe', 'Asia']\n",
    "}\n",
    "df_continents = pd.DataFrame(continent_data)\n",
    "\n",
    "# Merge the two DataFrames using 'country_code' as the key\n",
    "# how='left' keeps all rows from the olympics data, even if we didn't map their continent\n",
    "df_merged = pd.merge(df_olympics, df_continents, on='country_code', how='left')\n",
    "\n",
    "# Check the result to see the new 'continent' column\n",
    "df_merged[df_merged['continent'].notnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Pivot Tables\n",
    "# We want to see Countries as Rows, Years as Columns, and the Count of Medals as values\n",
    "pivot_medals = df_olympics.pivot_table(\n",
    "    index='country', \n",
    "    columns='year', \n",
    "    values='medal', \n",
    "    aggfunc='count', \n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Show a subset (first 5 countries, last 5 Olympic years)\n",
    "pivot_medals.iloc[:5, -5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Time Series Handling\n",
    "df_weather = pd.read_csv('pittsburgh-weather-2024.csv')\n",
    "\n",
    "# The 'Day' column is just \"Month Day\" (e.g., \"January 1\"). \n",
    "# We need to add the year and convert to datetime.\n",
    "df_weather['Date'] = pd.to_datetime(df_weather['Day'] + ', 2024', format='%B %d, %Y')\n",
    "\n",
    "# Set the new Date column as the index\n",
    "df_weather.set_index('Date', inplace=True)\n",
    "\n",
    "# 4. Resampling\n",
    "# 'M' stands for Month. We calculate the mean for every month.\n",
    "monthly_temps = df_weather['High'].resample('M').mean()\n",
    "\n",
    "monthly_temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Visualization\n",
    "# Plotting the resampled time series data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "monthly_temps.plot(marker='o', color='orange', linestyle='-')\n",
    "\n",
    "plt.title('Average Monthly High Temperature in Pittsburgh (2024)')\n",
    "plt.ylabel('Temperature (°F)')\n",
    "plt.xlabel('Month')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
